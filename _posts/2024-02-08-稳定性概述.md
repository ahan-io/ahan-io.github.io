---
layout: post
title: "稳定性概述"
author:       "Ahan"
date: 2024-02-08 00:00:00
header-img: "img/post-bg-2015.jpg"
header-style: text
catalog:      true
tags:
    - Architecture
    - Stability
---
# 什么是稳定性？

在分布式系统中，**稳定性（Stability）** 通常指系统在面对各种内部或外部扰动时，**持续提供预期功能与性能的能力**。

扰动可能来自硬件故障、软件缺陷、网络波动、流量突增、操作失误，甚至极端情况下的多重故障叠加。

一个高稳定性的系统不仅应能在事件发生时**快速恢复**，还应**尽量减少对用户体验的影响**，甚至实现“用户无感”的平滑过渡。

在数字化浪潮中，企业对云服务与基础设施的依赖程度日益加深。IT 基础设施的稳定性，已直接影响业务的连续性与用户信任。如今的云计算服务，已如“水和电”一般成为基础设施的一部分——一旦长时间中断，带来的影响往往是连锁的、系统性的。

## 行业中的典型事件 ⚙️

近年来，全球范围内的云服务与互联网基础设施，均曾出现过不同规模的服务异常。这些事件提醒我们，**再成熟的系统也无法做到绝对不出故障**。以下是公开报道中的几个典型案例：

- **2023年11月，某大型出行平台** 在高峰时段出现定位与网络异常，后经官方说明为“底层系统软件故障”。
- **2023年11月，某主流云服务提供商** 在部分地域出现控制台访问及 API 调用异常，核心业务一度受影响，约两小时后恢复。
- **2022年12月，某云厂商的香港可用区** 由于冷却系统异常触发消防系统，导致机房设备受损，影响持续约十小时。
- **2018年11月，AWS（亚马逊云服务）** 在韩国区域出现大规模中断，导致多家交易平台和网站暂时不可用。

> ⚙️（以上事件均来自公开新闻报道，示例仅用于技术讨论，不代表对相关企业的评论或立场。）
> 

这些案例表明，**稳定性是所有系统建设的底线**。它不仅关系客户体验与业务收入，更直接影响品牌的长期声誉。

# 为什么你需要关注稳定性建设？

在现代企业 IT 架构中，**稳定性已经不是附加指标，而是业务成败的分水岭**。

频繁的宕机、性能波动或数据不一致问题，会导致用户流失、营收受损、品牌受挫，甚至影响企业战略决策。

无论你采用的是公有云、私有云，还是混合云，分布式架构虽然带来了灵活性与弹性，但也引入了更多的不确定性。

**如何在复杂系统中保障业务连续性**，是每一支研发团队必须面对的挑战。

本书将系统介绍分布式系统稳定性建设的核心理念与方法，涵盖：

- 架构设计与防御性工程；
- 监控与可观测性；
- 故障演练与事后复盘；
- 流程与文化的制度化建设。

希望能为软件架构师、研发工程师、SRE 及 QA 提供可实践、可落地的体系化视角。

## 对不同角色的价值

- **研发工程师（Dev）**：通过理解稳定性原理，减少潜在缺陷，提高代码质量与可靠性。
- **运维与 SRE**：通过监控、自动化、配置优化与容灾机制，降低服务中断时间。
- **质量保障（QA）**：在测试中融入稳定性场景，如压力测试、容错验证，确保系统在异常条件下仍能稳定运行。
- **职场新人**：理解稳定性建设的体系，有助于建立工程思维，提高问题分析与解决能力。
- **求职者**：稳定性经验往往是面试中的加分项，展现出候选人的全局意识与工程成熟度。

# 如何衡量稳定性

评估系统稳定性时，常用以下核心指标：

1. **可靠性（Reliability）**：系统在一定时间内无故障运行的概率。常用指标包括故障率、平均无故障时间（MTBF）、平均修复时间（MTTR）。
2. **可用性（Availability）**：系统在给定时间内可正常使用的比例。通常以百分比形式表示。
3. **RTO（恢复时间目标）**：系统从停止到恢复的最长可接受时间。
4. **RPO（数据恢复点目标）**：可接受的最大数据丢失时间范围。

同时，还常见以下术语：

- **SLI（Service Level Indicator）**：服务水平指标，例如“正常响应的请求比例”。
- **SLO（Service Level Objective）**：围绕 SLI 制定的可量化目标，如“月度可用性≥99.95%”。
- **SLA（Service Level Agreement）**：服务协议，通常与客户签署，规定在未达标时的补偿方式。

在交流时，应注意区分，例如：

> ❌“你们服务的 SLA 是多少？”
> 
> 
> ✅“你们服务的可用性 SLO 是多少？”
> 

## 可用性 vs 可靠性

**可用性（Availability）** 指系统是否“可被使用”；

**可靠性（Reliability）** 指系统是否“持续无故障运行”。

二者虽相关，但关注点不同：

| 可用性级别 | 年度宕机时间 | 月宕机时间 |
| --- | --- | --- |
| 99% | 3.65天 | 7.2小时 |
| 99.9% | 8.76小时 | 43分钟 |
| 99.99% | 52.6分钟 | 4.3分钟 |
| 99.999% | 5.26分钟 | 26秒 |

> ⚙️ 云厂商通常以自然月为单位计算可用性，并据此定义服务补偿条款。
> 
> 
> 本节引用行业通用标准，不代表任何特定厂商的政策。
> 

可靠性可通过以下指标量化：

- **MTBF**（平均无故障时间）
- **MTTR**（平均修复时间）
- **MTTF**（平均失效时间）

两者关系为：

> Availability = MTBF / (MTBF + MTTR)
> 

示例说明：

- 若系统每小时崩溃 1 毫秒，则可用性极高（>99.9999%），但可靠性差。
- 若系统从不崩溃，却需每年停机维护两周，则可靠性强但可用性不足。

## 稳定性、可靠性、可用性的关系

| 属性 | 关注问题 | 关键指标 | 时间尺度 | 目标 |
| --- | --- | --- | --- | --- |
| 可靠性 | 输出是否正确且一致 | MTBF | 长期 | 确保系统持续无故障运行 |
| 可用性 | 服务是否可用、响应是否及时 | SLA / 正常运行时间 | 短期 | 确保随时可用、快速恢复 |
| 稳定性 | 异常下能否保持可用 | 抗压性 / 恢复速度 | 长期 + 短期 | 面对扰动仍保持稳定服务 |

![image.png](https://ahan-io.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F3841c813-6aff-406c-8c94-6fa3c0018b15%2F0230be5e-247e-4743-853d-4bf435bf7756%2Fimage.png?table=block&id=15deda9f-236a-80e3-8f35-f6a4765a9a81&spaceId=3841c813-6aff-406c-8c94-6fa3c0018b15&width=900&userId=&cache=v2)

## 5-10-30

对多数线上服务而言，内部常以“5-10-30”作为运维目标：

- **5分钟内发现问题**；
- **10分钟内定位原因**；
- **30分钟内恢复或止损**。

该目标并非标准，而是行业中常见的稳定性自我评估基线。

# 体系化建设

![image.png](https://ahan-io.notion.site/image/attachment%3A56eeeaa3-86c1-4fbf-9c95-0ddc38f51b1e%3Aimage.png?table=block&id=2b9eda9f-236a-805c-b847-f211ac1698c2&spaceId=3841c813-6aff-406c-8c94-6fa3c0018b15&width=1420&userId=&cache=v2)

系统的**稳定性**并非源于某一单一的技术突破，而是一项贯穿系统生命周期的**系统性工程**。它需要从顶层设计、编码实践、发布验证、到实时监控与事后学习的全流程投入。

笔者将稳定性建设视为一个**持续改进的工程哲学闭环**，并将其系统性地划分为四个核心阶段，它们与本书的几个部分紧密对应：

| **阶段名称** | **核心目标** | **关键行动点** |
| --- | --- | --- |
| 预防性设计 | 从根源上消除或隔离故障，提升系统的天然韧性。 | 架构弹性、SPOF避免、数据保护、防御性编程、重试/幂等设计。 |
| 验证与强化 | 主动发现并修复隐藏缺陷，确保系统具备抗打击能力。 | 单元测试、测试流水线、混沌测试、生产环境演练。 |
| 实时感知与应对 | 在故障发生时快速感知、定位和止损，将影响降到最低。 | 可观测性建设（Metrics, Trace, Log）、高价值告警、应急指挥、快速容灾切换。 |
| 规范与改进 | 将工程经验固化为流程和标准，确保稳定性成为一种习惯。 | 变更规范、事故等级划分、故障复盘（Postmortem）、将经验融入代码规范。 |